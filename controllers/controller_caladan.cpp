#define NODE 0
#define CORES 28
#define HALF 32
#define CONTS 32

#include <vector>
#include <iostream>
#include <unistd.h>
#include <string>
#include <cstdlib>
#include <fstream>
#include <sstream>
#include <time.h>
#include <cmath>
#include <cassert>

bool train = true;
int core_state[HALF*2];			
uint64_t last_alloc[CONTS][HALF*2];		// Last use time
uint64_t tsc;
bool exec_slowdown[CONTS];
bool queue_slowdown[CONTS];
bool queue_okay[CONTS];
int cpus[CONTS];
int lim[CONTS];

bool have_new_sample;


// Setup and node state
int num_containers;

// ContainerState should only contain the latency values.
struct containerState {
    float queue_metric;
    float exec_desired;
    // Current execution latency
    float avg_exec;
    float avg_execm;
    float avg_queue;    // Should not be needed.
};

containerState _ctr[CONTS];

// File names for the various things needed
std::string _cname[CONTS];      // Container name
std::string _snames[CONTS];     // Stats file names
std::string _limFile = "workload_qos_profile";	// Change this to the file generated by set_service_targets.cpp
std::string container_name_actual[CONTS];

// Resource change
std::string stats1 = "/home/cc/paper_setup/shared/";

// Things for defining whether resource changes have occured, these are used by the actual resource update fns
bool changed_core[CONTS];

// variables for cluster state
int cont_to_cluster[CONTS];         // container to cluster
int num_clusters;                   

void read_profile() {
  std::ifstream fpo(_limFile);
  std::string tmpStr;
  int idx;
  float exec, queue;
  std::string name;

  while(std::getline(fpo, tmpStr)) {
    std::stringstream linestream(tmpStr);
    linestream >> idx >> name >> exec >> queue;
    if(idx < num_containers) {
	_ctr[idx].exec_desired = 2.0*exec;	// Try 1.3 for the spike stuff if needed
	_ctr[idx].queue_metric = 1.45*queue;
    }
  }
  fpo.close();
}

/*
 * Functions for starting off with a predefined parititoning.
 */
int next = 0;
void init_cores(int idx, int cores) {
  int start = next;
  for(int i=0; i<cores; i++) {
    core_state[start] = idx; core_state[HALF+start] = idx;
    start++;
  }
  next = start;
  cpus[idx] = 2*cores; lim[idx] = 2*cores; changed_core[idx] = true;
}

void init_cluster() {
  next = 0;	// Reset pointer
  for(int i=0; i<CORES; i++) {
    core_state[i] = -1; core_state[i+HALF] = -1;
  }
  for(int i=CORES; i<HALF; i++) { 
    core_state[i] = -2; core_state[i+HALF] = -2;
  }
}

/* 
 * Functions for setting the allocations to the files/counters.
*/
inline std::string get_cpu_list(int i, bool isBg = false) {
    std::string str = "";
    bool first = true;
    if(isBg) {
        for(int c=0; c<HALF*2; c++) {
	  if(core_state[c] == -1) {
	    if(first) {
	      str += std::to_string(c);
              first = false;
	    } else {
              str += "," + std::to_string(c);
	    }
	  }
	}
    } else {
	int owner = i;
	//std::cout << "Inside: " << owner << " ---> " << _cname[i] << "\n";
        for(int c=0; c<HALF*2; c++) {
	  if(core_state[c] == owner) {
	    if(first) {
	      str += std::to_string(c);
              first = false;
	    } else {
              str += "," + std::to_string(c);
	    }
	  }
	}
    }
    return str;
} 

void do_all_allocations() {
    // Enforce core allocations
    // Each cluster must have at least one core to avoid pathological cond
    for(int i=0; i<num_clusters; i++) {
        if(changed_core[i] && cpus[i] > 0) {
            std::string str = ("docker update --cpuset-cpus " + get_cpu_list(i) + " ");
            for(int it=0; it<num_containers; it++) {
		if(cont_to_cluster[it] == i) {
		  if(get_cpu_list(i) == "") {
			printf("No cores allocated to cluster %d container %d\n", i, it);
			exit(-1);
		  }
		  //std::cout << str << container_name_actual[it] << "\n";
                  system((str + container_name_actual[it]).c_str());
		}
	    }
        }
    }
}

/* Caladan implementation
 */
void realloc_core(int core, int do_not_tread) {
  for(int i=0; i<CORES; i++) {
    if(core_state[i] == -1 && core_state[i+HALF] != do_not_tread) {
      // Found idle core, reallocate.
      int owner = core_state[core];
      changed_core[owner] = 1;
      core_state[i] = owner;
      core_state[core] = -1;
      last_alloc[owner][core] = tsc;  
      if(core >= HALF)
        last_alloc[owner][core-HALF] = tsc;  
      else
        last_alloc[owner][core+HALF] = tsc;  
      return;
    }
  }
  for(int i=HALF; i<HALF+CORES; i++) {
    if(core_state[i] == -1 && core_state[i-HALF] != do_not_tread) {
      // Found idle core, reallocate.
      int owner = core_state[core];
      changed_core[owner] = 1;
      core_state[i] = owner;
      core_state[core] = -1;
      last_alloc[owner][core] = tsc;  
      if(core >= HALF)
        last_alloc[owner][core-HALF] = tsc;  
      else
        last_alloc[owner][core+HALF] = tsc;  
      return;
    }
  }
}

void alloc_core(int core, int owner) {
  changed_core[owner] = 1;
  core_state[core] = owner;
  last_alloc[owner][core] = tsc;  
  if(core >= HALF)
    last_alloc[owner][core-HALF] = tsc;  
  else
    last_alloc[owner][core+HALF] = tsc;  
  cpus[owner]++;
}

void remove_core(int core, int owner) {
  changed_core[owner] = 1;
  core_state[core] = -1;
  cpus[owner]--;
}

void ht_ctlr() {
  bool free = false;
  for(int i=0; i<HALF*2; i++) {
    if((i >= CORES && i < HALF) || (i >= HALF+CORES && i < 2*HALF))
      continue;
    if(core_state[i] == 0)
      free = true;
  }
  if(!free)
    return;

  for(int i=0; i<num_clusters; i++) {
    if(exec_slowdown[i]) {
      for(int c=0; c<CORES; c++) {
        if(core_state[c] == i) {
          if(core_state[c+HALF] != i && core_state[c+HALF] != -1) {
	    // Sibling is not idle and belongs to someone else, realloc sibling proc and allocate ht to me!
	    // Once one core has been reallocated, go to next cluster.
	    realloc_core(c+HALF, i);
            goto next;
	  }
	}
      }
      for(int c=HALF; c<HALF+CORES; c++) {
        if(core_state[c] == i) {
          if(core_state[c-HALF] != i && core_state[c-HALF] != -1) {
	    // Sibling is not idle and belongs to someone else, realloc sibling proc and allocate ht to me!
	    // Once one core has been reallocated, go to next cluster.
	    realloc_core(c-HALF, i);
            goto next;
	  }
	}
      }
    }
    next: ;
  }
}

void top_level_alloc(int owner) {
  int i = (owner == -1) ? 0 : owner;
  int fin = (owner == -1) ? num_clusters : owner+1;

  for(; i<fin; i++) {
    if(owner != -1 || queue_slowdown[i]) {
      bool found = false;  //We want to allocate an extra core here.
      // First search for core where both hyperthreads are idle.
      for(int c=0; c<CORES; c++) {
	if(core_state[c] == -1 && core_state[c+HALF] == -1) {
	  alloc_core(c, i);
	  found = true;
	  break;
        }
      }
      // Then search for core where one of the hyperthreads is not taken by me.
      if(!found) {
        for(int c=0; c<CORES; c++) {
	  if(core_state[c] == -1 && core_state[c+HALF] != i) {
	    alloc_core(c, i);
	    found = true;
	    break;
	  }
	}
      }
      if(!found) {
        for(int c=HALF; c<HALF+CORES; c++) {
	  if(core_state[c] == -1 && core_state[c-HALF] != i) {
	    alloc_core(c, i);
	    found = true;
	    break;
	  }
	}
      }
      // Then search for the core with has been most recently used by me.
      if(!found) {
	uint64_t max_tsc = 0;
        int max_tsc_core = -1;
	for(int c=0; c<HALF*2; c++) {
          if((c >= CORES && c < HALF) || (c >= HALF+CORES))
            continue;
	  if(core_state[c] == -1) {
	    if(last_alloc[i][c] >= max_tsc) {
	      max_tsc = last_alloc[i][c];
	      max_tsc_core = c;
	    }
	  }
	}
        alloc_core(max_tsc_core, i);
      }
    }
  }
  return;
}

void bw_ctlr() {
  // Not implementing this, the bandwidth control doesn't work..
  ;
  /*
  if(total_bw_shortfall) {
    float min_bw = 1.0;
    int min_bw_cluster = -1;
    for(int i=0; i<num_clusters; i++) {
      if(min_bw >= bw[i]) {
	min_bw = bw[i];
	min_bw_cluster = i;
      }
    }
    top_level_alloc(min_bw_cluster);
  }*/
}

void top_level_yield() {
  for(int i=0; i<num_clusters; i++) {
    bool okay = (cpus[i] > lim[i]);
    if(queue_okay[i] && okay) {
      bool found = false;
      // First remove core where I hold both apirs.
      uint64_t min_tsc = tsc;
      int min_tsc_core = -1;
      for(int c=0; c<CORES; c++) {
        if(core_state[c] == i && core_state[c+HALF] == i) {
          if(last_alloc[i][c] < min_tsc) {
            min_tsc = last_alloc[i][c];
            min_tsc_core = c;
          }
        }
      }
      if(min_tsc_core != -1) {
	found = true;
	remove_core(min_tsc_core, i);
      }
      //Then remove cores where I hold one of the hyperthreads and the other one is not idle.
      if(!found) {
        for(int c=0; c<CORES; c++) {
	  if(core_state[c] == i && core_state[c+HALF] != -1) {
	    remove_core(c, i);
	    found = true;
	    break;
	  }
	}
      }
      if(!found) {
        for(int c=HALF; c<HALF+CORES; c++) {
	  if(core_state[c] == i && core_state[c-HALF] != -1) {
	    remove_core(c, i);
	    found = true;
	    break;
	  }
	}
      }
      // Finally, we have the cores whose pair is busy. Dealloc one of these.
      if(!found) {
        for(int c=0; c<CORES; c++) {
	  if(core_state[c] == i && core_state[c+HALF] == -1) {
	    remove_core(c, i);
	    found = true;
	    break;
	  }
	}
      }
      // Check upper half. Dealloc one of these.
      if(!found) {
        for(int c=HALF; c<HALF+CORES; c++) {
	  if(core_state[c] == i && core_state[c-HALF] == -1) {
	    remove_core(c, i);
	    found = true;
	    break;
	  }
	}
      }
    }
  }
  return;
}

/*
 * Functions which read system state and provide inputs for core inc./dec. functions
 */
void read_stats_file() {
  for(int i=0; i<num_clusters; i++) {
    queue_slowdown[i] = exec_slowdown[i] = false;
    queue_okay[i] = false;
  }
  have_new_sample = true;
  int read = 0; int same = 0;
 
  // Read all the stats files.
  for(int i=0; i<num_containers; i++) {
    bool issame = false; 

    int owner = cont_to_cluster[i];
    std::ifstream fp(_snames[i]);
    if(fp.fail()) {
        _ctr[i].avg_exec = -1;
        queue_okay[owner] = false;
    } 
    else {
      std::string tmpStr;
      std::getline(fp, tmpStr);
      if(tmpStr.size() < 5) {
	// Not reading real values yet, just set exec_okay
	queue_okay[owner] = false;
	continue;
      }
      read++;
      std::stringstream linestream(tmpStr);

      float blah1, blah2, blah3;
      linestream >> blah2 >> blah3 >> blah1;
      if(blah3 == _ctr[i].avg_exec && blah2 == _ctr[i].avg_execm && blah1 == _ctr[i].avg_queue) {
	same++;
	issame = true;
      }
      
      _ctr[i].avg_exec = blah3;
      _ctr[i].avg_execm = blah2;
      _ctr[i].avg_queue = blah1;

      float queue_metric = (_ctr[i].avg_exec)/(_ctr[i].avg_execm);
      queue_metric = queue_metric/_ctr[i].queue_metric;

      float exec_metric = (_ctr[i].avg_exec)/(_ctr[i].exec_desired);

      float HIGH = 1.04; float LOW = 0.98;
      // Containers with very small avg exec time (mongodb) can naturally have wild variations, do not upscale them
      if(_ctr[i].exec_desired < 0.002) { 
	 queue_slowdown[owner] = false;
         queue_okay[owner] = false;
      } else {
        if(exec_metric > 1.05 && !issame)
	   exec_slowdown[owner] = true; 
	if(queue_metric > HIGH && !issame)
	   queue_slowdown[owner] = true;
        if(queue_metric < LOW && !issame)
	   queue_okay[owner] = true;
      }
      fp.close(); 
    }
  }
  if(read == same)  have_new_sample = false;
}

void decide() {
  read_stats_file();
  if(have_new_sample) {
    top_level_yield();
    ht_ctlr();
    top_level_alloc(-1);
    do_all_allocations();
  }
}

/*
 * Initialization and profile update functions
 */
void set_up_names() {
    int t_num_clusters, t_num_containers;

    std::ifstream file("/home/cc/paper_setup/config/config_cluster");	// Change to name of the config file.

    // First read the file and find the actual container names. Write them into file "container_names". Not needed if container names match what is provided in the config file.
    std::string line, line2;
    std::getline(file, line);

    t_num_containers = std::stoi(line);
    std::getline(file, line);
    t_num_clusters = std::stoi(line);
    for(int i=0; i<t_num_containers; i++) {
      std::getline(file, line);
      std::stringstream linestream(line);

      std::string data, name;
      int id, this_node;

      linestream >> id >> this_node >> name >> data;
      if(this_node != NODE)
        continue;

      std::system(("docker inspect --format '{{.Name}}' $(docker ps -q) | grep " +  name + ">> container_names").c_str());
    }
    file.close();
}
void initialize() {
    int t_num_clusters, t_num_containers;
    std::ifstream file("/home/cc/paper_setup/config/config_social_cluster");
    std::ifstream file2("container_names");
    std::string line, line2;
    std::getline(file, line);
    t_num_containers = std::stoi(line);
    std::getline(file, line);
    t_num_clusters = std::stoi(line);

    num_clusters = 0; num_containers = 0;
    // Read the input file and set up things.
    int cnt=0; float discard;
    for(int i=0; i<t_num_containers; i++) {
      std::getline(file, line);
      std::stringstream linestream(line);
        
      int id, this_node;
      std::string name;
      int clusterID; int num_cores;

      linestream >> id >> this_node >> name;
      if(this_node != NODE)
        continue;
      
      std::getline(file2, line2); 
      _cname[cnt] = name;
      container_name_actual[cnt] = line2;
      
      linestream >> _ctr[cnt].exec_desired >> discard;
      linestream >> clusterID >> num_cores;

      cont_to_cluster[cnt] = clusterID;
      _ctr[cnt].avg_exec = _ctr[cnt].exec_desired;
      _snames[cnt] = stats1+name;

      init_cores(clusterID, num_cores);
      if(clusterID > num_clusters)
        num_clusters = clusterID;
      
      num_containers++;
      cnt++;
    }
    num_clusters++;
    file.close();
    file2.close();

    do_all_allocations();
}

/*
 * Main() function
 */
int main(int argc, char* argv[]) {
    int core_sum = 0;
    float full_sum = 0;
    float full_time = 0;
    struct timespec ts1, ts2, ts3;
    int i=0;

    float warmup = 30000;
    bool warmed = false;

    for(int i=0; i<CONTS; i++) {
      cpus[i] = 0;
    }
    set_up_names();
    initialize();
    read_profile();

    clock_gettime(CLOCK_REALTIME, &ts1);
   
    // Warm for 30s and then poll for 60s.
    do {
       clock_gettime(CLOCK_REALTIME, &ts2);
	i++;
       for(int ii=0; ii<num_clusters; ii++) {
           changed_core[ii] = false;
       }
       decide();
       usleep(100000);

       core_sum = 0;
       for(int ii=0; ii<HALF*2; ii++) {
	   if(core_state[ii] >= 0) {
	    core_sum++;
	   }
       }
	clock_gettime(CLOCK_REALTIME, &ts3);
	if ((ts3.tv_sec-ts1.tv_sec)*1000 + (ts3.tv_nsec-ts1.tv_nsec)/1000000.0 < warmup) {
	  full_sum += core_sum*((ts3.tv_sec-ts2.tv_sec)*1000000 + (ts3.tv_nsec-ts2.tv_nsec)/1000.0);
	  full_time += 1*((ts3.tv_sec-ts2.tv_sec)*1000000 + (ts3.tv_nsec-ts2.tv_nsec)/1000.0);
	} else {
	  if(!warmed) {
	    warmed = true;
	    printf("Resetting cluster\n");
	    init_cluster();
	    do_all_allocations();
 	    train = false;
    	    printf("Warmup Phase: CoreUsage (us-cores): %f, avg cores used: %f\n", full_sum, full_sum/full_time);
	    full_sum = 0; full_time = 0;
	  }
	  full_sum += core_sum*((ts3.tv_sec-ts2.tv_sec)*1000000 + (ts3.tv_nsec-ts2.tv_nsec)/1000.0);
	  full_time += 1*((ts3.tv_sec-ts2.tv_sec)*1000000 + (ts3.tv_nsec-ts2.tv_nsec)/1000.0);
	}
   } while (((ts3.tv_sec-ts1.tv_sec)*1000+(ts3.tv_nsec-ts1.tv_nsec)/1000000.0) < 90000);  
    printf("CoreUsage (us-cores): %f, avg cores used: %f\n", full_sum, full_sum/full_time);
    return -1;
}
